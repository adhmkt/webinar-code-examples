{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n42ScOAx0IAh"
      },
      "source": [
        "# Building a Generative AI Application with LlamaIndex and SingleStore\n",
        "\n",
        "Welcome to this in-depth guide on constructing a Generative AI application utilizing LlamaIndex and SingleStoreDB. This guide will provide a step-by-step walkthrough, code explanations, and best practices.\n",
        "\n",
        "## Overview\n",
        "LlamaIndex is a library dedicated to ingesting, indexing, and querying contextual information for Retrieval Augmented Generation (RAG). In synergy with SingleStoreDB, a scalable and SQL-compliant relational database system, it lays the foundation for building powerful generative AI applications. This combination facilitates real-time data processing and retrieval, essential for answering user queries efficiently. LlamaIndex is also cross compatible with Langchain, another popular library used for composing LLM inputs and outputs. We'll use both with SingleStore to build an end-to-end GenAI app.\n",
        "\n",
        "## What You'll Learn\n",
        "- Setting up the environment with the required packages and credentials.\n",
        "- Ingesting and indexing data using LlamaIndex for efficient retrieval.\n",
        "- Storing and managing data in SingleStoreDB.\n",
        "- Building a retrieval-based generative AI system to respond to user queries.\n",
        "\n",
        "## Prerequisites\n",
        "- Basic knowledge of Python programming.\n",
        "- Understanding of SQL databases.\n",
        "- Familiarity with generative AI concepts would be beneficial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CuScKOz2V--"
      },
      "source": [
        "Let's first install the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8gbadBPcVdq"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install llama-hub --quiet\n",
        "!pip install singlestoredb --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTyaBjaC2l4A"
      },
      "source": [
        "Then, let's set our OpenAI API Key. Note: the API keys used in this notebook are placeholders and invalid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9nIA0T2Pcbgv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGZQKeo02qiY"
      },
      "source": [
        "Next, we'll import the SingleStore vectorstore from Langchain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QgIcQgDOccgj"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import SingleStoreDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUlmrnw721oi"
      },
      "source": [
        "After importing SingleStore, we can ingest the docs for LlamaIndex into a new table. This takes three steps:\n",
        "\n",
        "1. Load raw HTML data using WebBaseLoader\n",
        "2. Chunk the text.\n",
        "3. Embed or vectorize the chunked text, then ingest it into SingleStore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i5ESqCtVcdv_"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://gpt-index.readthedocs.io/en/latest/\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hGBKa8m9cf37"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
        "all_splits = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_OQgOifPc4fp"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "os.environ[\"SINGLESTOREDB_URL\"] = \"admin:Naopassara0@svc-b0c3cf30-3e0a-4933-be43-ab1e7f5e2117-dml.aws-saopaulo-1.svc.singlestore.com:3306/minhaDB\"\n",
        "\n",
        "# vectorstore = SingleStoreDB.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
        "vectorstore = SingleStoreDB(embedding=OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zX7dL2r3UNW"
      },
      "source": [
        "Now, we'll use Llama Index to retrieve and query from SingleStore using the SingleStoreReader, a lightweight embedding lookup tool for SingleStore databases ingested with content and vector data.\n",
        "\n",
        "Note that the full SingleStore vectorstore integration with Llama Index for ingesting and indexing is coming soon!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQy1IgKvhUB4",
        "outputId": "26109ce0-5974-46b5-e025-e4d9dedd8bc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/fplopez/pinokio/bin/miniconda/lib/python3.10/site-packages/llama_index/utilities/sql_wrapper.py:110: SAWarning: Did not recognize type 'JSON' of column 'metadata'\n",
            "  self._metadata.reflect(\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "NullType() takes no arguments",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m \u001b[39mimport\u001b[39;00m download_loader\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m SingleStoreReader \u001b[39m=\u001b[39m download_loader(\u001b[39m\"\u001b[39m\u001b[39mSingleStoreReader\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reader \u001b[39m=\u001b[39m SingleStoreReader(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     scheme\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmysql\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     host\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msvc-b0c3cf30-3e0a-4933-be43-ab1e7f5e2117-dml.aws-saopaulo-1.svc.singlestore.com\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     port\u001b[39m=\u001b[39;49m\u001b[39m3306\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     user\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39madmin\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mNaopassara0\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     dbname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mminhaDB\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     table_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     content_field\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     vector_field\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvector\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fplopez/Python/webinar-code-examples/Building_a_Gen_AI_App_with_LlamaIndex_and_SingleStore.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/llama_index/download/llamahub_modules/singlestore/base.py:62\u001b[0m, in \u001b[0;36mSingleStoreReader.__init__\u001b[0;34m(self, scheme, host, port, user, password, dbname, table_name, content_field, vector_field)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDatabaseReader \u001b[39m=\u001b[39m download_loader(\u001b[39m\"\u001b[39m\u001b[39mDatabaseReader\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDatabaseReader(\n\u001b[1;32m     63\u001b[0m     scheme\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscheme,\n\u001b[1;32m     64\u001b[0m     host\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhost,\n\u001b[1;32m     65\u001b[0m     port\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport,\n\u001b[1;32m     66\u001b[0m     user\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser,\n\u001b[1;32m     67\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpassword,\n\u001b[1;32m     68\u001b[0m     dbname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdbname,\n\u001b[1;32m     69\u001b[0m )\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/llama_hub/database/base.py:68\u001b[0m, in \u001b[0;36mDatabaseReader.__init__\u001b[0;34m(self, sql_database, engine, uri, scheme, host, port, user, password, dbname, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     uri \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mscheme\u001b[39m}\u001b[39;00m\u001b[39m://\u001b[39m\u001b[39m{\u001b[39;00muser\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mpassword\u001b[39m}\u001b[39;00m\u001b[39m@\u001b[39m\u001b[39m{\u001b[39;00mhost\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mport\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdbname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muri \u001b[39m=\u001b[39m uri\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msql_database \u001b[39m=\u001b[39m SQLDatabase\u001b[39m.\u001b[39;49mfrom_uri(uri, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     69\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must provide either a SQLDatabase, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39ma SQL Alchemy Engine, a valid connection URI, or a valid \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mset of credentials.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m     )\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/llama_index/utilities/sql_wrapper.py:133\u001b[0m, in \u001b[0;36mSQLDatabase.from_uri\u001b[0;34m(cls, database_uri, engine_args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct a SQLAlchemy engine from URI.\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m _engine_args \u001b[39m=\u001b[39m engine_args \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m--> 133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(create_engine(database_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_engine_args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/llama_index/utilities/sql_wrapper.py:110\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[0;34m(self, engine, schema, metadata, ignore_tables, include_tables, sample_rows_in_table_info, indexes_in_table_info, custom_table_info, view_support, max_string_length)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata \u001b[39m=\u001b[39m metadata \u001b[39mor\u001b[39;00m MetaData()\n\u001b[1;32m    109\u001b[0m \u001b[39m# including view support if view_support = true\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metadata\u001b[39m.\u001b[39;49mreflect(\n\u001b[1;32m    111\u001b[0m     views\u001b[39m=\u001b[39;49mview_support,\n\u001b[1;32m    112\u001b[0m     bind\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine,\n\u001b[1;32m    113\u001b[0m     only\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_usable_tables),\n\u001b[1;32m    114\u001b[0m     schema\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_schema,\n\u001b[1;32m    115\u001b[0m )\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:5788\u001b[0m, in \u001b[0;36mMetaData.reflect\u001b[0;34m(self, bind, schema, views, only, extend_existing, autoload_replace, resolve_fks, **dialect_kwargs)\u001b[0m\n\u001b[1;32m   5781\u001b[0m     load \u001b[39m=\u001b[39m [\n\u001b[1;32m   5782\u001b[0m         name\n\u001b[1;32m   5783\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m only\n\u001b[1;32m   5784\u001b[0m         \u001b[39mif\u001b[39;00m extend_existing \u001b[39mor\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m current\n\u001b[1;32m   5785\u001b[0m     ]\n\u001b[1;32m   5786\u001b[0m \u001b[39m# pass the available tables so the inspector can\u001b[39;00m\n\u001b[1;32m   5787\u001b[0m \u001b[39m# choose to ignore the filter_names\u001b[39;00m\n\u001b[0;32m-> 5788\u001b[0m _reflect_info \u001b[39m=\u001b[39m insp\u001b[39m.\u001b[39;49m_get_reflection_info(\n\u001b[1;32m   5789\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   5790\u001b[0m     filter_names\u001b[39m=\u001b[39;49mload,\n\u001b[1;32m   5791\u001b[0m     available\u001b[39m=\u001b[39;49mavailable,\n\u001b[1;32m   5792\u001b[0m     kind\u001b[39m=\u001b[39;49mkind,\n\u001b[1;32m   5793\u001b[0m     scope\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mpreloaded\u001b[39m.\u001b[39;49mengine_reflection\u001b[39m.\u001b[39;49mObjectScope\u001b[39m.\u001b[39;49mANY,\n\u001b[1;32m   5794\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdialect_kwargs,\n\u001b[1;32m   5795\u001b[0m )\n\u001b[1;32m   5796\u001b[0m reflect_opts[\u001b[39m\"\u001b[39m\u001b[39m_reflect_info\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _reflect_info\n\u001b[1;32m   5798\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m load:\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:2006\u001b[0m, in \u001b[0;36mInspector._get_reflection_info\u001b[0;34m(self, schema, filter_names, available, _reflect_info, **kw)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         res \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2003\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m   2005\u001b[0m info \u001b[39m=\u001b[39m _ReflectionInfo(\n\u001b[0;32m-> 2006\u001b[0m     columns\u001b[39m=\u001b[39mrun(\n\u001b[1;32m   2007\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_multi_columns, check_filter_names_from_meth\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   2008\u001b[0m     ),\n\u001b[1;32m   2009\u001b[0m     pk_constraint\u001b[39m=\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_multi_pk_constraint),\n\u001b[1;32m   2010\u001b[0m     foreign_keys\u001b[39m=\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_multi_foreign_keys),\n\u001b[1;32m   2011\u001b[0m     indexes\u001b[39m=\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_multi_indexes),\n\u001b[1;32m   2012\u001b[0m     unique_constraints\u001b[39m=\u001b[39mrun(\n\u001b[1;32m   2013\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_multi_unique_constraints, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2014\u001b[0m     ),\n\u001b[1;32m   2015\u001b[0m     table_comment\u001b[39m=\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_multi_table_comment, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m   2016\u001b[0m     check_constraints\u001b[39m=\u001b[39mrun(\n\u001b[1;32m   2017\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_multi_check_constraints, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m     ),\n\u001b[1;32m   2019\u001b[0m     table_options\u001b[39m=\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_multi_table_options, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m   2020\u001b[0m     unreflectable\u001b[39m=\u001b[39munreflectable,\n\u001b[1;32m   2021\u001b[0m )\n\u001b[1;32m   2022\u001b[0m \u001b[39mif\u001b[39;00m _reflect_info:\n\u001b[1;32m   2023\u001b[0m     _reflect_info\u001b[39m.\u001b[39mupdate(info)\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:1992\u001b[0m, in \u001b[0;36mInspector._get_reflection_info.<locals>.run\u001b[0;34m(meth, optional, check_filter_names_from_meth)\u001b[0m\n\u001b[1;32m   1990\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1991\u001b[0m     \u001b[39mif\u001b[39;00m has_result:\n\u001b[0;32m-> 1992\u001b[0m         res \u001b[39m=\u001b[39m meth(filter_names\u001b[39m=\u001b[39;49m_fn, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m   1993\u001b[0m         \u001b[39mif\u001b[39;00m check_filter_names_from_meth \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m res:\n\u001b[1;32m   1994\u001b[0m             \u001b[39m# method returned no result data.\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m             \u001b[39m# skip any future call methods\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m             has_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:921\u001b[0m, in \u001b[0;36mInspector.get_multi_columns\u001b[0;34m(self, schema, filter_names, kind, scope, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Return information about columns in all objects in the given\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[39mschema.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39m.. seealso:: :meth:`Inspector.get_columns`\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operation_context() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m--> 921\u001b[0m     table_col_defs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m(\n\u001b[1;32m    922\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mget_multi_columns(\n\u001b[1;32m    923\u001b[0m             conn,\n\u001b[1;32m    924\u001b[0m             schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    925\u001b[0m             filter_names\u001b[39m=\u001b[39;49mfilter_names,\n\u001b[1;32m    926\u001b[0m             kind\u001b[39m=\u001b[39;49mkind,\n\u001b[1;32m    927\u001b[0m             scope\u001b[39m=\u001b[39;49mscope,\n\u001b[1;32m    928\u001b[0m             info_cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo_cache,\n\u001b[1;32m    929\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw,\n\u001b[1;32m    930\u001b[0m         )\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instantiate_types(table_col_defs\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    933\u001b[0m \u001b[39mreturn\u001b[39;00m table_col_defs\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/engine/default.py:1099\u001b[0m, in \u001b[0;36mDefaultDialect._default_multi_reflect\u001b[0;34m(self, single_tbl_method, connection, kind, schema, filter_names, scope, **kw)\u001b[0m\n\u001b[1;32m   1095\u001b[0m key \u001b[39m=\u001b[39m (schema, table)\n\u001b[1;32m   1096\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[39myield\u001b[39;00m (\n\u001b[1;32m   1098\u001b[0m         key,\n\u001b[0;32m-> 1099\u001b[0m         single_tbl_method(\n\u001b[1;32m   1100\u001b[0m             connection, table, schema\u001b[39m=\u001b[39;49mschema, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw\n\u001b[1;32m   1101\u001b[0m         ),\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[1;32m   1103\u001b[0m \u001b[39mexcept\u001b[39;00m exc\u001b[39m.\u001b[39mUnreflectableTableError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1104\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m unreflectable:\n",
            "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget_columns\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:97\u001b[0m, in \u001b[0;36mcache\u001b[0;34m(fn, self, con, *args, **kw)\u001b[0m\n\u001b[1;32m     95\u001b[0m ret: _R \u001b[39m=\u001b[39m info_cache\u001b[39m.\u001b[39mget(key)\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     ret \u001b[39m=\u001b[39m fn(\u001b[39mself\u001b[39;49m, con, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m     98\u001b[0m     info_cache[key] \u001b[39m=\u001b[39m ret\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py:2960\u001b[0m, in \u001b[0;36mMySQLDialect.get_columns\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n\u001b[1;32m   2958\u001b[0m \u001b[39m@reflection\u001b[39m\u001b[39m.\u001b[39mcache\n\u001b[1;32m   2959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_columns\u001b[39m(\u001b[39mself\u001b[39m, connection, table_name, schema\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m-> 2960\u001b[0m     parsed_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parsed_state_or_create(\n\u001b[1;32m   2961\u001b[0m         connection, table_name, schema, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw\n\u001b[1;32m   2962\u001b[0m     )\n\u001b[1;32m   2963\u001b[0m     \u001b[39mif\u001b[39;00m parsed_state\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m   2964\u001b[0m         \u001b[39mreturn\u001b[39;00m parsed_state\u001b[39m.\u001b[39mcolumns\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py:3220\u001b[0m, in \u001b[0;36mMySQLDialect._parsed_state_or_create\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n\u001b[1;32m   3217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_parsed_state_or_create\u001b[39m(\n\u001b[1;32m   3218\u001b[0m     \u001b[39mself\u001b[39m, connection, table_name, schema\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw\n\u001b[1;32m   3219\u001b[0m ):\n\u001b[0;32m-> 3220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_parser(\n\u001b[1;32m   3221\u001b[0m         connection,\n\u001b[1;32m   3222\u001b[0m         table_name,\n\u001b[1;32m   3223\u001b[0m         schema,\n\u001b[1;32m   3224\u001b[0m         info_cache\u001b[39m=\u001b[39;49mkw\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39minfo_cache\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   3225\u001b[0m     )\n",
            "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m_setup_parser\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:97\u001b[0m, in \u001b[0;36mcache\u001b[0;34m(fn, self, con, *args, **kw)\u001b[0m\n\u001b[1;32m     95\u001b[0m ret: _R \u001b[39m=\u001b[39m info_cache\u001b[39m.\u001b[39mget(key)\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     ret \u001b[39m=\u001b[39m fn(\u001b[39mself\u001b[39;49m, con, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m     98\u001b[0m     info_cache[key] \u001b[39m=\u001b[39m ret\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py:3256\u001b[0m, in \u001b[0;36mMySQLDialect._setup_parser\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n\u001b[1;32m   3252\u001b[0m     columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_describe_table(\n\u001b[1;32m   3253\u001b[0m         connection, \u001b[39mNone\u001b[39;00m, charset, full_name\u001b[39m=\u001b[39mfull_name\n\u001b[1;32m   3254\u001b[0m     )\n\u001b[1;32m   3255\u001b[0m     sql \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39m_describe_to_create(table_name, columns)\n\u001b[0;32m-> 3256\u001b[0m \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mparse(sql, charset)\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/reflection.py:48\u001b[0m, in \u001b[0;36mMySQLTableDefinitionParser.parse\u001b[0;34m(self, show_create, charset)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mr?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m, show_create):\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreparer\u001b[39m.\u001b[39minitial_quote):\n\u001b[0;32m---> 48\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_column(line, state)\n\u001b[1;32m     49\u001b[0m     \u001b[39m# a regular table options line\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39melif\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m):\n",
            "File \u001b[0;32m~/pinokio/bin/miniconda/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/reflection.py:284\u001b[0m, in \u001b[0;36mMySQLTableDefinitionParser._parse_column\u001b[0;34m(self, line, state)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(col_type, SET) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m type_args:\n\u001b[1;32m    282\u001b[0m         type_kw[\u001b[39m\"\u001b[39m\u001b[39mretrieve_as_bitwise\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m type_instance \u001b[39m=\u001b[39m col_type(\u001b[39m*\u001b[39;49mtype_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtype_kw)\n\u001b[1;32m    286\u001b[0m col_kw \u001b[39m=\u001b[39m {}\n\u001b[1;32m    288\u001b[0m \u001b[39m# NOT NULL\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: NullType() takes no arguments"
          ]
        }
      ],
      "source": [
        "from llama_index import download_loader\n",
        "\n",
        "SingleStoreReader = download_loader(\"SingleStoreReader\")\n",
        "\n",
        "reader = SingleStoreReader(\n",
        "    scheme=\"mysql\",\n",
        "    host=\"svc-b0c3cf30-3e0a-4933-be43-ab1e7f5e2117-dml.aws-saopaulo-1.svc.singlestore.com\",\n",
        "    port=3306,\n",
        "    user=\"admin\",\n",
        "    password=\"Naopassara0\",\n",
        "    dbname=\"minhaDB\",\n",
        "    table_name=\"embeddings\",\n",
        "    content_field=\"content\",\n",
        "    vector_field=\"vector\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejV-Yn3R4AwL"
      },
      "source": [
        "Let's test it out. This function takes a natural language query as input, then does the following:\n",
        "\n",
        "1. Embed the query using the OpenAI Embedding model, `text-embedding-ada-002` by default.\n",
        "2. Ingest the documents into a Llama Index list index, a data structure that returns all documents into the context.\n",
        "3. Initialize the index as a Llama Index query engine, which uses the `gpt-3.5-turbo` OpenAI LLM by default to understand the query and provided context, then generate a response.\n",
        "4. Returns the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PQ9earK8yPzB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from llama_index import ListIndex\n",
        "\n",
        "def ask_llamaindex_docs(query):\n",
        "\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "  search_embedding = embeddings.embed_query(query)\n",
        "  documents = reader.load_data(search_embedding=json.dumps(str(search_embedding)))\n",
        "\n",
        "  index = ListIndex(documents)\n",
        "\n",
        "  query_engine = index.as_query_engine()\n",
        "\n",
        "  response = query_engine.query(query)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtFluQttpk7a",
        "outputId": "d15c3225-1a09-47b8-a531-8c9c6db7e61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama Index is a data framework for LLM applications to ingest, structure, and access private or domain-specific data.\n"
          ]
        }
      ],
      "source": [
        "print(ask_llamaindex_docs(\"What is Llama Index?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKtIf_lC1bcw",
        "outputId": "b6ca291f-92fb-4cd2-b849-229eed7ba7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data indexes in Llama Index are modules that allow users to organize and retrieve their data efficiently. These indexes can be customized and extended to fit the specific needs of the users.\n"
          ]
        }
      ],
      "source": [
        "print(ask_llamaindex_docs(\"What are data indexes in Llama Index?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs9btjMB10If",
        "outputId": "95314fc2-35e8-4c5c-bc25-cdc71b018edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query engines in Llama Index are components that handle different types of queries on the data stored in the index. They include the Graph Query Engine, Multistep Query Engine, Retriever Query Engine, Transform Query Engine, Router Query Engine, Retriever Router Query Engine, Sub Question Query Engine, SQL Join Query Engine, Flare Query Engine, Citation Query Engine, Knowledge Graph Query Engine, SQL Query Engine, and Pandas Query Engine. Each query engine is designed to handle specific types of queries and provide efficient and accurate results.\n"
          ]
        }
      ],
      "source": [
        "print(ask_llamaindex_docs(\"What are query engines in Llama Index?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT4HR_t36sNy"
      },
      "source": [
        "# Tips and Tricks\n",
        "\n",
        "## Chat engines\n",
        "\n",
        "Chat with your data conversationally with Llama Index Chat Engines, which allow for follow-ups and further questions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "rmygl6G67WYw",
        "outputId": "76ec0289-477a-4e6d-d8c4-00088099f804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Entering Chat REPL =====\n",
            "Type \"exit\" to exit.\n",
            "\n",
            "Human: What is Llama Index?\n",
            "Assistant: LlamaIndex is an open-source library that provides tools and APIs for building and deploying large-scale search and retrieval systems. It allows users to ingest, index, and query large amounts of data efficiently. LlamaIndex supports various types of data stores, including document stores, key-value stores, and graph stores. It also provides different indexing techniques and retrieval models to optimize search performance. LlamaIndex is designed to be flexible and customizable, allowing users to tailor the system to their specific needs. It is suitable for both beginners and advanced users, offering a high-level API for quick and easy usage, as well as lower-level APIs for customization and extension.\n",
            "\n",
            "Human: What can Llama Index do?\n",
            "Assistant: LlamaIndex offers a range of capabilities for building and deploying search and retrieval systems. Here are some key features and functionalities of LlamaIndex:\n",
            "\n",
            "1. Data Ingestion: LlamaIndex provides tools for ingesting large amounts of data from various sources, including document stores, key-value stores, and graph stores.\n",
            "\n",
            "2. Indexing: LlamaIndex supports different indexing techniques, such as inverted indexes, forward indexes, and graph indexes. These indexes enable efficient and fast retrieval of relevant information.\n",
            "\n",
            "3. Querying: LlamaIndex allows users to perform complex queries on the indexed data. It supports various query types, including keyword search, phrase search, fuzzy search, and advanced search operators.\n",
            "\n",
            "4. Customization: LlamaIndex offers a modular architecture that allows users to customize and extend different components of the system. This includes data connectors, indices, retrievers, query engines, and reranking modules.\n",
            "\n",
            "5. Scalability: LlamaIndex is designed to handle large-scale data and can scale horizontally to accommodate growing data volumes and user demands.\n",
            "\n",
            "6. Performance Optimization: LlamaIndex provides optimization techniques to improve search performance, such as query rewriting, caching, and result ranking strategies.\n",
            "\n",
            "7. Evaluation: LlamaIndex includes tools for evaluating the performance of search and retrieval systems. It offers modules for measuring relevancy, correctness, embedding similarity, and other evaluation metrics.\n",
            "\n",
            "8. Integration: LlamaIndex can be integrated with other tools and frameworks, such as deep learning models, knowledge graph query engines, and language chains, to enhance the capabilities of the system.\n",
            "\n",
            "Overall, LlamaIndex empowers users to build efficient and customizable search and retrieval systems, making it suitable for a wide range of applications and use cases.\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-94e987d92ce5>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mchat_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_chat_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mchat_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/chat_engine/types.py\u001b[0m in \u001b[0;36mchat_repl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Assistant: {response}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Human: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "query = \"What is Llama Index?\"\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "search_embedding = embeddings.embed_query(query)\n",
        "documents = reader.load_data(search_embedding=json.dumps(str(search_embedding)))\n",
        "\n",
        "index = ListIndex(documents)\n",
        "\n",
        "chat_engine = index.as_chat_engine(chat_mode='context')\n",
        "\n",
        "chat_engine.chat_repl()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3BIgvoC8o6U"
      },
      "source": [
        "## Finetune Embeddings\n",
        "\n",
        "Improve your retrieval performance by 5-10% using a finetuned embedding model. Though a full implementation is outside the scope of this webinar, at a high level, you will:\n",
        "\n",
        "1. Split your data into train and validation datasets.\n",
        "2. Generate synthetic QA embedding pairs.\n",
        "3. Finetune your model using Llama Index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf_3UIth_B0j"
      },
      "outputs": [],
      "source": [
        "# Your data goes here\n",
        "train_dataset = generate_qa_embedding_pairs(train_nodes)\n",
        "val_dataset = generate_qa_embedding_pairs(val_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "FqZnxwey-qS0"
      },
      "outputs": [],
      "source": [
        "from llama_index.finetuning import SentenceTransformersFinetuneEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgdmYCFh-q9C"
      },
      "outputs": [],
      "source": [
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"BAAI/bge-small-en\",\n",
        "    model_output_path=\"test_model\",\n",
        "    val_dataset=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwAsIF9s_GJI"
      },
      "outputs": [],
      "source": [
        "finetune_engine.finetune()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrlj9KSn_Hnb"
      },
      "outputs": [],
      "source": [
        "embed_model = finetune_engine.get_finetuned_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ-A880W6iLK"
      },
      "source": [
        "****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KW64Bkm_PXf"
      },
      "source": [
        "## Data Agents\n",
        "\n",
        "Data Agents are agents in LlamaIndex that can reason over your data and perform predefined tasks, with the ability to read and modify your data. They can:\n",
        "\n",
        "- Perform automated search and retrieval over different types of data - unstructured, semi-structured, and structured.\n",
        "\n",
        "- Calling any external service API in a structured fashion, and processing the response + storing it for later.\n",
        "\n",
        "We'll create a simple agent with access to the `ask_llamaindex_docs` function we created earlier as a tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "mhKFkh6JAFYS"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms import OpenAI\n",
        "from llama_index.agent import ReActAgent\n",
        "from llama_index.tools import QueryEngineTool, ToolMetadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "-oPT5nm0AGON"
      },
      "outputs": [],
      "source": [
        "llamaindex_docs_tool = QueryEngineTool(\n",
        "    query_engine=index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"llamaindex_docs\",\n",
        "        description=\"Provides access to the docs for Llama Index, a library for ingesting, indexing, and querying data for LLMs.\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "s_9E-vfBA3Od"
      },
      "outputs": [],
      "source": [
        "agent = ReActAgent.from_tools([llamaindex_docs_tool], verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "1MDc-YQaBMZH"
      },
      "outputs": [],
      "source": [
        "agent.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIBOT2ySA8sr",
        "outputId": "271cd471-49c2-4760-f00f-0188bf13b7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;200m\u001b[1;3mThought: I need to use a tool to help me answer the question.\n",
            "Action: llamaindex_docs\n",
            "Action Input: {'input': 'Llama Index'}\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mObservation: LlamaIndex is a tool that provides APIs for both beginner and advanced users. It allows beginners to easily ingest and query their data with just a few lines of code. Advanced users can customize and extend various modules, such as data connectors, indices, retrievers, query engines, and reranking modules, to suit their specific needs. LlamaIndex also supports different types of stores, including document stores, index stores, key-value stores, and graph stores. It offers various tutorials and guides to help users understand and utilize its features effectively.\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mResponse: Llama Index is a tool that provides APIs for both beginner and advanced users. It allows beginners to easily ingest and query their data with just a few lines of code. Advanced users can customize and extend various modules, such as data connectors, indices, retrievers, query engines, and reranking modules, to suit their specific needs. Llama Index also supports different types of stores, including document stores, index stores, key-value stores, and graph stores. It offers various tutorials and guides to help users understand and utilize its features effectively.\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AgentChatResponse(response='Llama Index is a tool that provides APIs for both beginner and advanced users. It allows beginners to easily ingest and query their data with just a few lines of code. Advanced users can customize and extend various modules, such as data connectors, indices, retrievers, query engines, and reranking modules, to suit their specific needs. Llama Index also supports different types of stores, including document stores, index stores, key-value stores, and graph stores. It offers various tutorials and guides to help users understand and utilize its features effectively.', sources=[], source_nodes=[])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.chat(\"What is Llama Index?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URn-hFCNBBL7"
      },
      "outputs": [],
      "source": [
        "agent.chat(\"Tell me about it's capabiltiies\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
